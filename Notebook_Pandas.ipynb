{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook_Pandas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHfABnnBQq7AJIivVNr+zw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prang-nin/dataAnalysis/blob/main/Notebook_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pandas library \n",
        "# **Data indexing and Selection**\n",
        "- `pd.Series`\n",
        "✅ Mapping collection of index to the collection of values\n",
        "Similarly to dictionary \n",
        "- `data.keys()` \n",
        "✅ Get all keys list (object type)\n",
        "- `data.items()` \n",
        "✅ Get tuple of all pairs value and its key \n",
        "- `data['key']` = value  ✅ similar to dictionary syntax\n",
        "- `data['start_key':'end_key'] `\n",
        "✅ Get all values in the range of those key or using index also works aswell.\n",
        "- `data[key1, key2]` ✅Get all values that are mapped from key1 and key2\n",
        "- `data[(condition1)&(condition2)]` ✅ Get all values that satisfied both condition 1& 2\n",
        "# The different between loc and iloc\n",
        "- `data.loc[index]`   ✅indexing use loc will start index from 1,2,3 ,...\n",
        "- `data.iloc[index] `  ✅ indexing use iloc will start index from 0,1,2,3 ,..."
      ],
      "metadata": {
        "id": "6XZeGX81HxKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.Series([0.25, 0.5, 0.75, 1.0], index=['a', 'b', 'c', 'd'])\n",
        "print('the pandas series data 1')\n",
        "print(data)\n",
        "#Get a'l index list \n",
        "print('List of key in the series :',data.keys())\n",
        "#Get list of pairs (key, value)\n",
        "print('List of all items in the series :', list(data.items()))\n",
        "# select value that has key ='a'\n",
        "print('value of key \"a\" is :', data['a'])\n",
        "# Select values that has key start from 'a' to 'c' order is matter \n",
        "print('items that has key \"a\" to \"c\" are :')\n",
        "print(data['a':'c'])\n",
        "# Select values from index 0 to index 1 (not include 2)\n",
        "print(\"The first two items of the series are:\")\n",
        "print(data[0:2])\n",
        "# Select values that > 0.3 but <0.8\n",
        "print(\"items that has value between 0.3 and 0.8 are :\")\n",
        "print(data[(data>0.3)&(data<0.8)])\n",
        "\n",
        "data2 = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])\n",
        "print('the pandas series data 2')\n",
        "print(data2)\n",
        "# loc : starting index = 1\n",
        "# iloc : starting index = 0\n",
        "print('The value of first item')\n",
        "print(data2.loc[1])\n",
        "print('The value of second item')\n",
        "print(data2.iloc[1])\n"
      ],
      "metadata": {
        "id": "VYI6BfgmIeOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataFrame\n",
        "DataFrame is two-dimensional array that behave like the dictionary of Series \n",
        "  \n",
        "✅ Select a specific column by specified attribute_name\n",
        "- `data.attribute_name `   \n",
        "\n",
        "✅ For add a new attribute that can be calculated from specified attributes\n",
        "- *data[new_attribute]* = *data['att1']* operation with *data['att2']*\n",
        " \n",
        "✅ To get all values from dataframe\n",
        "- `data.values` \n",
        "\n",
        "✅ To get all the values in that particular row\n",
        "- `data.values[index]`  \n",
        "\n",
        "✅ To get all the values in that particular column\n",
        "- `data.values['attr_name'] `\n",
        "\n",
        "✅ To select table using index\n",
        "- `data.iloc[start_row:end_row , start_col:end_col] `\n",
        "\n",
        "✅ To select table using attribute name\n",
        "- `data.loc['start_row_name':'end_row_name', 'start_col_name':'end_col_name']  `\n",
        "\n",
        "✅ Transpose the table\n",
        "- `data.T`\n",
        "\n",
        "**Remark** that if the index is not specified, it means select from beginning/ till the end\n"
      ],
      "metadata": {
        "id": "WYfywkIDMuvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
        "                  'New York': 141297, 'Florida': 170312,\n",
        "                  'Illinois': 149995})\n",
        "pop = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
        "                 'New York': 19651127, 'Florida': 19552860,\n",
        "                 'Illinois': 12882135})\n",
        "data = pd.DataFrame({'area':area, 'pop':pop})\n",
        "print('Data table')\n",
        "print(data)\n",
        "# Select only attribute 'area'\n",
        "print('Area')\n",
        "print(data.area)\n",
        "\n",
        "# Add density as new attribute\n",
        "data['density'] = data['area']/data['pop']\n",
        "print('Updated table with new attribute')\n",
        "print(data)\n",
        "\n",
        "# Slice only first 3 row and first 2 column \n",
        "print('Sliced table for area and population of first 3 rows')\n",
        "print(data.iloc[:3,:2])\n",
        "\n",
        "# slice from first row until illinois and first column until population\n",
        "print('Sliced row from first row to \"illinois\" and Sliced column from first attribute to \"pop\" :')\n",
        "print(data.loc[:'Illinois', :'pop'])\n",
        "\n",
        "#select all instance that has density more than 100 and sliced only \"pop\" and \"density\" columns\n",
        "print('Select all instance that has density more than 100 and sliced only \"pop\" and \"density\" columns')\n",
        "print(data.loc[data.density > 100, ['pop', 'density']])\n",
        "#Change value of row '0' and column '2' to 90\n",
        "data.iloc[0, 2] = 90\n",
        "#Transpose of table\n",
        "data.T"
      ],
      "metadata": {
        "id": "5L0EWCHUM_y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Operation in Pandas**\n",
        "**Index alignment in Series**\n",
        "- For operation between instance from a different `pd.Series`, the matched index is used for referencing. \n",
        "- If the matched index **does not** exist, it will give **'Nan'**\n",
        "- the **'Nan'** can be replaced using` A.add(B, fill_value=0)`, this will fill the value for any elements that missing with **'0'**\n",
        "- the **'Nan'** can be replaced using` A.add(B, fill_value=mean)`, this will fill the value for any elements that missing with **'mean'**\n",
        "where mean can be caluculated using mean = `data.stack().mean()` where data is a DataFrame\n",
        "\n",
        "**Index alignment in DataFrame**\n",
        "\n",
        "✅ Generate consistent random integer within specific range and size\n",
        "- `np.random.RandomState(42).randint(lowest_value, highest_value, size)`\n",
        "\n",
        "✅ Create DataFrame using the generated array and column list\n",
        "- `pd.DataFrame( numpy array , columns=list('AB'))`\n",
        "\n",
        "**Operation between DataFrame and Series**\n",
        "- In Pandas, the operation is row-wise by default but can change to column by defind *axis=0*\n",
        "\n",
        "✅ Subtract each **column** with the value of column 'R' \n",
        "- `df.subtract(df['R'], axis=0) `\n",
        "\n",
        "✅ Subtract each **row** with the value of first row\n",
        "- `df.subtract(df[0]) `"
      ],
      "metadata": {
        "id": "k_TwpL9P5WyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#index alignment with series\n",
        "A = pd.Series([2, 4, 6], index=[0, 1, 2])\n",
        "B = pd.Series([1, 3, 5], index=[1, 2, 3])\n",
        "print(\"Sum of 2 Series :\")\n",
        "print(A + B)\n",
        "# Replacing Nan with filling the missing value with 0\n",
        "print(\"Fix Nan\")\n",
        "print(A.add(B, fill_value =0))\n",
        "\n",
        "#index alignment with DataFrame\n",
        "# a random number generator that will pull random number from distribution with consistent pseudonumber\n",
        "A = pd.DataFrame(np.random.RandomState(42).randint(0, 20, (2, 2)), columns=list('AB'))\n",
        "print(\"DataFrame of random interger within [0,20] , size 2x2\")\n",
        "print(A)\n",
        "B = pd.DataFrame(np.random.RandomState(42).randint(0, 10, (3, 3)), columns=list('BAC'))\n",
        "print(\"DataFrame of random interger within [0,10] , size 3x3\")\n",
        "print(B)\n",
        "# row subtract\n",
        "print(\"subtract DataFrame with first row\")\n",
        "print(B.subtract(B.iloc[0]))\n",
        "# column subtract\n",
        "print(\"subtract DataFrame with column 'A'\")\n",
        "print(B.subtract(B['A'], axis =0) )"
      ],
      "metadata": {
        "id": "o1sO2FgOItqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Missing Data\n",
        "**Operating on Null Value**\n",
        "\n",
        "▶ Detecting Null value\n",
        "\n",
        ": Generate a boolean mask indicating missing value and return **Boolean** as an output\n",
        "- `data.isnull()`\n",
        "- `data.notnull()`\n",
        "\n",
        "▶ Droping Null value\n",
        "- `data.dropna()`\n",
        "\n",
        "Alternatively, dropna() function can specific dropping condition\n",
        "- `df.dropna(axis='columns', how='all')` \n",
        ": Drop columns that have 'Nan' for all instances\n",
        "-  `df.dropna(axis='columns', how='any')` \n",
        ": Drop columns that have at least one 'Nan' \n",
        "\n",
        "▶ Filling Null value\n",
        "\n",
        "- `data.fillna(0)`: Replace 'Nan' with 0\n",
        "- `data.fillna(method='ffill')` : Replace 'Nan' with the value of previous instance\n",
        "- `data.fillna(method='bfill')` : Replace 'Nan' with the value of next instance\n",
        "\n",
        "Similarly with row-wise, axis = 1 can be used to switch in to column-wise\n",
        "- `data.fillna(method='ffill', axis = 1)` : use previous column\n",
        "- `data.fillna(method='bfill', axis = 1)` : use next column"
      ],
      "metadata": {
        "id": "QAFqiJ3-YMsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarcal-Indexing\n",
        "\n",
        "**MultiIndex creation** (multiple methods)\n",
        "1. Define a list of index array \n",
        "- `pd.DataFrame(array, index=[first_index_list, second_index_list], columns=['col_name1', 'col_name2'])`\n",
        "2. Using MultiIndex method\n",
        "- `pd.MultiIndex.from_arrays([['a', 'a', 'b', 'b'], [1, 2, 1, 2]])`\n",
        "- `pd.MultiIndex.from_tuples([('a', 1), ('a', 2), ('b', 1), ('b', 2)])`\n",
        "- `pd.MultiIndex.from_product([['a', 'b'], [1, 2]])`\n",
        "\n",
        "**MultiIndex slicing**\n",
        "- DataFrame can be sliced by using multiple index \n",
        "\n",
        "**Stacking and Unstacking**\n",
        "- `data.unstack()` : obtionally the level of unstack can be identified\n",
        "- `data.stack()`   : re-unstack()\n",
        "\n",
        "**Index setting and reset**\n",
        "\n",
        "✅ reset the index by using specified column (like a primary key)\n",
        "- `updated_data = data.reset_index(name='col_name')`\n",
        "\n",
        "✅ Set an multiIndex  (combination of index as a primary key)\n",
        "- `updated_data.set_index(['col_name1', 'col_name2'])`\n",
        "\n",
        "**Data aggregation on Multi-index**\n",
        "\n",
        "⭐ built-in aggregation method like mean(), sum(), max(), min() can be used to aggregated subset of data by specified the *level* parameter\n",
        "- `data_mean = data.mean(level='index_level')` (will be removed soon)\n",
        "- `data_mean = data.groupby(level ='index_level).mean()`\n",
        "\n",
        "and also the method above can be operated as column-wise by specified axis = 1\n"
      ],
      "metadata": {
        "id": "drtmHoKxi9SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#method 1 using list of array\n",
        "df = pd.DataFrame(np.random.rand(4, 2), index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]], columns=['data1', 'data2'])\n",
        "print(df)\n",
        "      \n",
        "#method 2 using multiIndex\n",
        "A = pd.MultiIndex.from_arrays([['a', 'a', 'b', 'b'], [1, 2, 1, 2]])\n",
        "df2 = pd.DataFrame(np.random.rand(4, 2), index= A , columns=['data1', 'data2'])\n",
        "print(df2)\n",
        "\n",
        "#method 2 Using multiIndex for columns\n",
        "index = pd.MultiIndex.from_product([[2013, 2014], [1, 2]], names=['year', 'visit'])\n",
        "columns = pd.MultiIndex.from_product([['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],  names=['subject', 'type'])\n",
        "df3 = pd.DataFrame(np.random.rand(4,6), index = index, columns = columns)\n",
        "print(df3)\n",
        "\n",
        "# Slice subject Guido and type HR\n",
        "print(\"Sliced data table only subject 'Guido' and type 'HR' :\")\n",
        "print(df3['Guido','HR'])\n",
        "# slice using iloc\n",
        "print(\"Slice first two columns and first two instance\")\n",
        "print(df3.iloc[:2, :2])\n",
        "print(\"Slice every instance with the subject 'Bob' with type 'HR'\")\n",
        "print(df3.loc[:, ('Bob', 'HR')])\n",
        "# find mean of each instance group by year\n",
        "print(\" Find the mean of each instance groupby 'year' \")\n",
        "print(df3.groupby(level ='year').mean())\n",
        "print(\" Find the mean of each instance groupby 'year' \")"
      ],
      "metadata": {
        "id": "wTvCnxw1kRY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining Datasets\n",
        "\n",
        "**simple concatenate**\n",
        "- `pd.concat([data1, data2])`: can be applied for `Series` or `DataFrame`\n",
        "\n",
        "▶ For joining tables, Natural join is applied by default\n",
        "- `pd.concat([data1, data2], axis =1 )` : join the column\n",
        "- `pd.concat([data1, data2], join ='inner' )`: specify the join-type\n",
        "- `pd.concat([data1, data2], join_axes=[df.columns] )` : specify joined column\n",
        "\n",
        "**Append method**\n",
        "- `new_dataFrame = df1.append(df2)`\n",
        "same result as `pd.concat([df1,df2])`\n",
        "\n",
        "Remark that : append() in Pandas will create a new object unlike append() in Python List that will modify the original data\n",
        "\n",
        "**Using Merge**\n",
        "- `pd.merge(df1, df2)`\n",
        "- `pd.merge(df1, df2, on='key_column')` ▶ join using key column\n",
        "- `pd.merge(df1, df2, left_on=\"key_column\", right_on=\"key_column\"))` ▶ join using key columns by specified joining side\n",
        "- `pd.merge(df1, df2).drop('drop_colum', axis=1)`\n",
        "▶ Drop a specific column\n",
        "\n",
        "- `pd.merge(df1,df2, how='inner') ` ▶  Specified join-type\n"
      ],
      "metadata": {
        "id": "lG7i9J-CvW2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# simple concantenate series\n",
        "ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n",
        "ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])\n",
        "print(pd.concat([ser1, ser2]))\n",
        "\n",
        "def make_df(cols, ind):\n",
        "    \"\"\"Quickly make a DataFrame\"\"\"\n",
        "    data = {c: [str(c) + str(i) for i in ind]\n",
        "            for c in cols}\n",
        "    return pd.DataFrame(data, ind)\n",
        "# Simple join row-wise\n",
        "df1 = make_df('AB', [1, 2])\n",
        "df2 = make_df('AB', [3, 4])\n",
        "print(pd.concat([df1, df2]))\n",
        "\n",
        "# Simple join column-wise \n",
        "df3 = make_df('AB', [0, 1])\n",
        "df4 = make_df('CD', [0, 1])\n",
        "print(pd.concat([df3,df4], axis =1))\n",
        "\n",
        "#with join (Natural join)\n",
        "df5 = make_df('ABC', [1, 2])\n",
        "df6 = make_df('BCD', [3, 4])\n",
        "print(pd.concat([df5,df6]))\n"
      ],
      "metadata": {
        "id": "wQa4evJ_vMe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregation and Grouping\n",
        "\n",
        "✅ Compute common aggregated \n",
        "- `data.dropna().describe()` \n",
        "\n",
        "✅ Some built-in aggregation method\n",
        "- `count()` : total number of items\n",
        "- `first() `, `last()` : first and last item\n",
        "- `mean()` , `median()` : mean and median\n",
        "- `min() `, `max()` : minimum and maximum\n",
        "- `std()`, `var() `: std and variance\n",
        "- `mad()` : mean absolute deviation\n",
        "- `prod()` : product of all items\n",
        "- `sum()` : sum of all items\n",
        "\n",
        "✅ Using groupby with aggregation\n",
        "- `df.groupby('key').sum()` : For example, sum of all items group by 'key'\n",
        "- `df.groupby('key')['val_col'].mean()` : Find mean of 'val_col' groupby 'key'\n",
        "- `df.groupby('key').aggregate({'data1': 'min','data2': 'max'})`\n",
        "\n",
        "✅ Using filtering\n",
        "- `df['data1'].std() > 4` \n",
        "\n",
        "▶ Select the table which has std of 'data1' column greater than 4, and drop all the instance that has std less than 4\n",
        "\n",
        "✅ Using transformation\n",
        "- `df.groupby('key').transform(lambda x: x - x.mean())`\n",
        "\n",
        "▶ Transform data into an output that has the same shape as input (in this example is to centralized data by subtracting with mean)\n",
        "\n",
        "✅ Apply function that not a built-in using `.apply()`\n",
        "- `df.groupby('key').apply(created_function)`"
      ],
      "metadata": {
        "id": "pNxCyf7K2Xqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pivot table\n",
        "\n",
        "**Pivot table**\n",
        "\n",
        "- `DataFrame.pivot_table(data, values=None, index=None, columns=None,aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')`\n",
        "\n",
        "**Multi-level pivot table**\n",
        "\n",
        "- `pd.cut()`\n",
        "Using to reduce some dimension\n",
        "```\n",
        "# This is formatted as code\n",
        "age = pd.cut(titanic['age'], [0, 18, 80])\n",
        "titanic.pivot_table('survived', ['sex', age], 'class')\n",
        "```\n",
        "\n",
        "- `pd.qcut()`\n",
        "Using to reduce some dimension and automatically compute quatile\n",
        "```\n",
        "# This is formatted as code\n",
        "fare = pd.qcut(titanic['fare'], 2)\n",
        "titanic.pivot_table('survived', ['sex', age], [fare, 'class'])\n",
        "```\n"
      ],
      "metadata": {
        "id": "9MJ9GU5bFmAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorized string operation\n",
        "- `str` method using `.str.method()`\n",
        " which have various return values\n",
        "\n",
        "**List of Pandas str method()**\n",
        "```\n",
        "# This is formatted as code\n",
        "len()\tlower()\ttranslate()\tislower()\n",
        "ljust()\tupper()\tstartswith()\tisupper()\n",
        "rjust()\tfind()\tendswith()\tisnumeric()\n",
        "center()\trfind()\tisalnum()\tisdecimal()\n",
        "zfill()\tindex()\tisalpha()\tsplit()\n",
        "strip()\trindex()\tisdigit()\trsplit()\n",
        "rstrip()\tcapitalize()\tisspace()\tpartition()\n",
        "lstrip()\tswapcase()\tistitle()\trpartition()\n",
        "```\n",
        "example:\n",
        "- `data.str.lower()`  : change all string into lowercase\n",
        "\n",
        "**Additional `str` method**\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "match()\t #Call re.match() on each element, returning a boolean.\n",
        "extract()\t#Call re.match() on each element, returning matched groups as strings.\n",
        "findall()\t#Call re.findall() on each element\n",
        "replace()\t#Replace occurrences of pattern with some other string\n",
        "contains()\t#Call re.search() on each element, returning a boolean\n",
        "count()\t#Count occurrences of pattern\n",
        "split()\t#Equivalent to str.split(), but accepts regexps\n",
        "rsplit()\t#Equivalent to str.rsplit(), but accepts regexps\n",
        "```\n",
        " **Miscellaneous `str `method**\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "get()\t#Index each element\n",
        "slice()\t#Slice each element\n",
        "slice_replace()\t#Replace slice in each element with passed value\n",
        "cat()\t#Concatenate strings\n",
        "repeat()\t#Repeat values\n",
        "normalize()\t#Return Unicode form of string\n",
        "pad()\t#Add whitespace to left, right, or both sides of strings\n",
        "wrap()\t#Split long strings into lines with length less than a given width\n",
        "join()\t#Join strings in each element of the Series with passed separator\n",
        "get_dummies()\t#extract dummy variables as a dataframe\n",
        "\n",
        "```\n",
        "\n",
        "**Slicing with `str` method**\n",
        "- Slice the character \n",
        "\n",
        "Example : Slice first 3 character \n",
        "`df.str.slice(0, 3)` is equivalent to `df.str[0:3]` \n",
        "\n",
        "- Get the position i\n",
        "\n",
        "Example : Get the position i\n",
        "\n",
        " `df.str.get(i)` is equivalent to  `df.str[i]`\n",
        "\n",
        "Example : Split str using `split()`\n",
        "\n",
        "`df.str.split() `\n",
        " : if not indicate any delimiter, it will use space by default\n",
        "\n",
        "Example : Get the first entry\n",
        "\n",
        "`df.str.split().str.get(0)`\n",
        "\n",
        "Example : Get the last entry\n",
        "\n",
        "`df.str.split().str.get(-1)`\n",
        "\n"
      ],
      "metadata": {
        "id": "zMG5HUzpGV0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time series\n",
        "\n",
        "**Native python dates and times**\n",
        "\n",
        "✅ Get the datetime object\n",
        "- Using `datetime`\n",
        "```\n",
        "# This is formatted as code\n",
        "from datetime import datetime\n",
        "datetime(year=2015, month=7, day=4)\n",
        "```\n",
        "- Using `dateutil`\n",
        "```\n",
        "# This is formatted as code\n",
        "from dateutil import parser\n",
        "date = parser.parse(\"4th of July, 2015\")\n",
        "```\n",
        "✅ Print it out in string format\n",
        "- `date.strftime('%d')`\n",
        "- %d for day, %m for month , %y year with last 2 digit, %Y year for 4 digits\n",
        "- https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
        "\n",
        "# Datetime in Numpy\n",
        "\n",
        "- Get the output in `datetime64` type using time series in Numpy\n",
        "```\n",
        "# This is formatted as code\n",
        "import numpy as np\n",
        "date = np.array('2015-07-04', dtype=np.datetime64)\n",
        "```\n",
        "\n",
        "# Pandas Time Series : Indexing by time\n",
        "\n",
        "Incase that we want to index our data with timestamp, we can create a `Series` object with time as an index. \n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "index = pd.DatetimeIndex(['2014-07-04', '2014-08-04',\n",
        "                          '2015-07-04', '2015-08-04'])\n",
        "data = pd.Series([0, 1, 2, 3], index=index)\n",
        "```\n",
        "We can slice our data using time index \n",
        "```\n",
        "# This is formatted as code\n",
        "data['2015'] # This will return series objects that have time index containg '2015' as a year\n",
        "```\n",
        "\n",
        "# Pandas Timeseries Data structure\n",
        "\n",
        "✅Invoke datat into datetime object\n",
        "- `pd.to_datetime() `\n",
        "\n",
        "✅ Convert `DatetimeIndex `to `PeriodtimeIndex`\n",
        "- `dates.to_period('D')` #  Indicate the frequency to daily\n",
        "\n",
        "# Regular sequences: `pd.date_range()`\n",
        "\n",
        "✅ Create regular date sequences for timestamp\n",
        "- `pd.date_range('start_date' , 'end_date')`\n",
        "- `pd.date_range('start_date' , period = number )`\n",
        "```\n",
        "# This is formatted as code\n",
        "pd.date_range('2015-07-03', '2015-07-10')\n",
        "pd.date_range('2015-07-03', periods=8)\n",
        "```\n",
        "✅ Create regular date sequences for period and duration\n",
        "\n",
        "- `pd.period_range('start_date', period = number, freq = '')`\n",
        "- `pd.timedelta_range(start, period = number, freq='')`\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "pd.period_range('2015-07', periods=8, freq='M')\n",
        "pd.timedelta_range(0, periods=10, freq='H')\n",
        "```\n",
        "\n",
        "**Frequency and Offsets**\n",
        "\n",
        "frequency can be specified by any desired frequency spacing\n",
        "```\n",
        "# This is formatted as code\n",
        "pd.timedelta_range(0, periods=9, freq=\"2H30T\")\n",
        "```\n",
        "\n",
        "# Resampling, Shifting, windowing\n",
        "\n",
        "✅ Data aggregation method \n",
        "\n",
        "- `resample() ` \n",
        "✅ Data selction method \n",
        "- `asfreq()`\n",
        "```\n",
        "data.resample('BA').mean()\n",
        "data.asfreq('BA')\n",
        "# BA is frequency type - Business year end\n",
        "```\n",
        "✅ Time-shift\n",
        "- `shift()`  : For shift the data\n",
        "- `tshift() ` : For shift the index (time)\n",
        "\n",
        "✅ Rolling windows\n",
        "- `rolling()` : For statistically rolling of the data"
      ],
      "metadata": {
        "id": "3tiRat1Idbv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High Performance Pandas \n",
        "\n",
        "- `pd.eval()`  # High performance dataframe operation expression\n",
        "\n",
        "▶ Arithmetics operators\n",
        "\n",
        "▶Comparison operators\n",
        "\n",
        "▶Bitwise operators\n",
        "\n",
        "▶And , Or in Boolean expression\n",
        "\n",
        "▶Accessing to object attributes and index\n",
        "\n",
        "**DataFrame.eval() for column-wise**\n",
        "```\n",
        "# This is formatted as code\n",
        "result1 = (df['A'] + df['B']) / (df['C'] - 1)\n",
        "result2 = pd.eval(\"(df.A + df.B) / (df.C - 1)\")\n",
        "np.allclose(result1, result2)\n",
        "```\n",
        "**Assign a new column with values that computed from another columns**\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "df.eval('D = (A + B) / C', inplace=True)\n",
        "df.head()\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "- `pd.query()` \n",
        "\n",
        "▶ Similar to marking with function but able to work with evaulated string\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "result2 = df.query('A < 0.5 and B < 0.5')\n",
        "np.allclose(result1, result2)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "jhxZrYEUxsrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "nrows, ncols = 100000, 100\n",
        "rng = np.random.RandomState(42)\n",
        "df1, df2, df3, df4 = (pd.DataFrame(rng.rand(nrows, ncols)) for i in range(4))\n",
        "%timeit df1 + df2 + df3 + df4\n",
        "%timeit pd.eval('df1 + df2 + df3 + df4')"
      ],
      "metadata": {
        "id": "PIDK5l_8Bec5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "rng = np.random.RandomState(42)\n",
        "df1, df2, df3, df4, df5 = (pd.DataFrame(rng.randint(0, 1000, (100, 3))) for i in range(5))\n",
        "result1 = (df1 < df2) & (df2 <= df3) & (df3 != df4)\n",
        "result2 = pd.eval('df1 < df2 <= df3 != df4')\n",
        "print(\"Are they give same result?\")\n",
        "print(np.allclose(result1, result2))\n",
        "%timeit result1\n",
        "%timeit result2"
      ],
      "metadata": {
        "id": "JHB0T5ngB6dD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}